<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.4" />
<title>reclab.environments.latent_factors API documentation</title>
<meta name="description" content="Contains the implementation for the Latent Behavior environment â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>reclab.environments.latent_factors</code></h1>
</header>
<section id="section-intro">
<p>Contains the implementation for the Latent Behavior environment.</p>
<p>In this environment users and items both have latent vectors, and
the rating is determined by the inner product. Users and item both
have bias terms, and there is an underlying bias as well.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Contains the implementation for the Latent Behavior environment.

In this environment users and items both have latent vectors, and
the rating is determined by the inner product. Users and item both
have bias terms, and there is an underlying bias as well.
&#34;&#34;&#34;
import collections
import json
import os

import numpy as np

from . import environment
from .. import data_utils
from ..recommenders import LibFM


class LatentFactorBehavior(environment.DictEnvironment):
    &#34;&#34;&#34;An environment where users and items have latent factors and biases.

    Ratings are generated as
    r = clip( &lt;p_u, q_i&gt; + b_u + b_i + b_0 )
    where p_u is a user&#39;s latent factor, q_i is an item&#39;s latent factor,
    b_u is a user bias, b_i is an item bias, and b_0 is a global bias.

    Parameters
    ----------
    latent_dim : int
        Size of latent factors p, q.
    num_users : int
        The number of users in the environment.
    num_items : int
        The number of items in the environment.
    rating_frequency : float
        The proportion of users that will need a recommendation at each step.
        Must be between 0 and 1.
    num_init_ratings : int
        The number of ratings available from the start. User-item pairs are randomly selected.
    noise : float
        The standard deviation of the noise added to ratings.
    affinity_change : float
        How much the user&#39;s latent factor is shifted towards that of an item.
    memory_length : int
        The number of recent items a user remembers which affect the rating.
    boredom_threshold : int
        The size of the inner product between a new item and an item in the
        user&#39;s history to trigger a boredom response.
    boredom_penalty : float
        The factor on the penalty on the rating when a user is bored. The penalty
        is the average of the values which exceed the boredom_threshold, and the decrease
        in rating is the penalty multiplied by this factor.
    user_dist_choice : str
        The choice of user distribution for selecting online users. By default, the subset of
        online users is chosen from a uniform distribution. Currently supports normal and lognormal.

    &#34;&#34;&#34;

    def __init__(self, latent_dim, num_users, num_items,
                 rating_frequency=0.02, num_init_ratings=0,
                 noise=0.0, memory_length=0, affinity_change=0.0,
                 boredom_threshold=0, boredom_penalty=0.0, user_dist_choice=&#39;uniform&#39;):
        &#34;&#34;&#34;Create a Latent Factor environment.&#34;&#34;&#34;
        super().__init__(rating_frequency, num_init_ratings, memory_length, user_dist_choice)
        self._latent_dim = latent_dim
        self._num_users = num_users
        self._num_items = num_items
        self._noise = noise
        self._affinity_change = affinity_change
        self._boredom_threshold = boredom_threshold
        self._boredom_penalty = boredom_penalty
        if self._memory_length &gt; 0:
            self._boredom_penalty /= self._memory_length
        self._user_factors = None
        self._user_biases = None
        self._item_factors = None
        self._item_biases = None
        self._offset = None

    @property
    def name(self):
        &#34;&#34;&#34;Name of environment, used for saving.&#34;&#34;&#34;
        return &#39;latent&#39;

    def _get_dense_ratings(self):  # noqa: D102
        ratings = (self._user_factors @ self._item_factors.T + self._user_biases[:, np.newaxis] +
                   self._item_biases[np.newaxis, :] + self._offset)
        # Compute the boredom penalties.
        item_norms = np.linalg.norm(self._item_factors, axis=1)
        normalized_items = self._item_factors / item_norms[:, np.newaxis]
        similarities = normalized_items @ normalized_items.T
        similarities -= self._boredom_threshold
        similarities[similarities &lt; 0] = 0
        penalties = self._boredom_penalty * similarities
        for user_id in range(self._num_users):
            for item_id in self._user_histories[user_id]:
                if item_id is not None:
                    ratings[user_id] -= penalties[item_id]

        return ratings

    def _get_rating(self, user_id, item_id):
        &#34;&#34;&#34;Compute user&#39;s rating of item based on model.

        Parameters
        ----------
        user_id : int
            The id of the user making the rating.
        item_id : int
            The id of the item being rated.

        Returns
        -------
        rating : int
            The rating the item was given by the user.

        &#34;&#34;&#34;
        raw_rating = (self._user_factors[user_id] @ self._item_factors[item_id]
                      + self._user_biases[user_id] + self._item_biases[item_id] + self._offset)

        # Compute the boredom penalty.
        boredom_penalty = 0
        for item_id_hist in self._user_histories[user_id]:
            item_factor = self._item_factors[item_id_hist]
            if item_factor is not None:
                similarity = ((self._item_factors[item_id] @ item_factor)
                              / np.linalg.norm(item_factor)
                              / np.linalg.norm(self._item_factors[item_id]))
                if similarity &gt; self._boredom_threshold:
                    boredom_penalty += (similarity - self._boredom_threshold)
        boredom_penalty *= self._boredom_penalty
        rating = np.clip(raw_rating - boredom_penalty + self._dynamics_random.randn() *
                         self._noise, 1, 5)

        return rating

    def _rate_item(self, user_id, item_id):
        &#34;&#34;&#34;Get a user to rate an item and update the internal rating state.

        Parameters
        ----------
        user_id : int
            The id of the user making the rating.
        item_id : int
            The id of the item being rated.

        Returns
        -------
        rating : int
            The rating the item was given by the user.

        &#34;&#34;&#34;
        rating = self._get_rating(user_id, item_id)

        # Updating underlying affinity
        self._user_factors[user_id] = ((1.0 - self._affinity_change) * self._user_factors[user_id]
                                       + self._affinity_change * self._item_factors[item_id])
        return rating

    def _reset_state(self):
        &#34;&#34;&#34;Reset the state of the environment.&#34;&#34;&#34;
        user_factors, user_bias, item_factors, item_bias, offset = self._generate_latent_factors()
        self._user_factors = user_factors
        self._user_biases = user_bias
        self._item_factors = item_factors
        self._item_biases = item_bias
        self._offset = offset

        self._users = collections.OrderedDict((user_id, np.zeros(0))
                                              for user_id in range(self._num_users))
        self._items = collections.OrderedDict((item_id, np.zeros(0))
                                              for item_id in range(self._num_items))

    def _generate_latent_factors(self):
        &#34;&#34;&#34;Generate random latent factors.&#34;&#34;&#34;
        # Initialization size determined such that ratings generally fall in 0-5 range
        factor_sd = np.sqrt(np.sqrt(0.5 / self._latent_dim))
        # User latent factors are normally distributed
        user_bias = self._init_random.normal(loc=0., scale=0.5, size=self._num_users)
        user_factors = self._init_random.normal(loc=0., scale=factor_sd,
                                                size=(self._num_users, self._latent_dim))
        # Item latent factors are normally distributed
        item_bias = self._init_random.normal(loc=0., scale=0.5, size=self._num_items)
        item_factors = self._init_random.normal(loc=0., scale=factor_sd,
                                                size=(self._num_items, self._latent_dim))
        # Shift up the mean
        offset = 3.0
        return user_factors, user_bias, item_factors, item_bias, offset


class DatasetLatentFactor(LatentFactorBehavior):
    &#34;&#34;&#34;An environment where user behavior is based on a dataset.

    Latent factor model of behavior with parameters fit directly from full dataset.

    Parameters
    ----------
    name : str
        The name of the dataset. Must be one of: &#39;ml-100k&#39;, &#39;ml-10m&#39;, &#39;lastfm&#39;.
    latent_dim : int
        Size of latent factors p, q.
    datapath : str
        The path to the directory containing datafiles
    force_retrain : bool
        Forces retraining the latent factor model
    max_num_users : int
        The maximum number of users for the environment, if not the number in the dataset.
    max_num_items : int
        The maximum number of items for the environment, if not the number in the dataset.

    &#34;&#34;&#34;

    def __init__(self, name, latent_dim=128, datapath=data_utils.DATA_DIR, force_retrain=False,
                 max_num_users=np.inf, max_num_items=np.inf, **kwargs):
        &#34;&#34;&#34;Create a ML100K Latent Factor environment.&#34;&#34;&#34;
        self.dataset_name = name
        if name == &#39;ml-100k&#39;:
            self.datapath = os.path.expanduser(os.path.join(datapath, &#39;ml-100k&#39;))
            latent_dim = 100 if latent_dim is None else latent_dim
            self._full_num_users = 943
            self._full_num_items = 1682
            # These parameters are the result of tuning.
            reg = 0.1
            learn_rate = 0.005
            self.train_params = dict(bias_reg=reg, one_way_reg=reg, two_way_reg=reg,
                                     learning_rate=learn_rate, num_iter=100)
        elif name == &#39;ml-10m&#39;:
            self.datapath = os.path.expanduser(os.path.join(datapath, &#39;ml-10M100K&#39;))
            latent_dim = 128 if latent_dim is None else latent_dim
            self._full_num_users = 69878
            self._full_num_items = 10677
            # these parameters are presented in &#34;On the Difficulty of Baselines&#34; by Rendle et al.
            reg = 0.04
            learn_rate = 0.003
            self.train_params = dict(bias_reg=reg, one_way_reg=reg, two_way_reg=reg,
                                     learning_rate=learn_rate, num_iter=128)
        elif name == &#39;lastfm&#39;:
            self.datapath = os.path.expanduser(os.path.join(datapath, &#39;lastfm-dataset-1K&#39;))
            latent_dim = 128 if latent_dim is None else latent_dim
            self._full_num_users = 992
            self._full_num_items = 177023
            # These parameters are presented in &#34;Recommendations and User Agency&#34; by Dean et al.
            reg = 0.08
            learn_rate = 0.001
            self.train_params = dict(bias_reg=reg, one_way_reg=reg, two_way_reg=reg,
                                     learning_rate=learn_rate, num_iter=128)
        else:
            raise ValueError(&#39;dataset name not recognized&#39;)
        self._force_retrain = force_retrain

        num_users = min(self._full_num_users, max_num_users)
        num_items = min(self._full_num_items, max_num_items)

        super().__init__(latent_dim, num_users, num_items, **kwargs)

    @property
    def name(self):
        &#34;&#34;&#34;Name of environment, used for saving.&#34;&#34;&#34;
        return &#39;latent-{}&#39;.format(self.dataset_name)

    def _generate_latent_factors(self):
        full_model_params = dict(num_user_features=0, num_item_features=0, num_rating_features=0,
                                 max_num_users=self._full_num_users,
                                 max_num_items=self._full_num_items,
                                 num_two_way_factors=self._latent_dim, **self.train_params)
        if self._num_users &lt; self._full_num_users or self._num_items &lt; self._full_num_items:
            reduced_num_users_items = (min(self._num_users, self._full_num_users),
                                       min(self._num_items, self._full_num_items))
        else:
            reduced_num_users_items = None
        # TODO: This is another source of randomness that isn&#39;t accounted for by our seeds.
        # We probably want to make it more obvious that we need to snapshot the output when
        # we want consistency across experiments.
        return generate_latent_factors_from_data(self.dataset_name, self.datapath,
                                                 full_model_params, self._init_random,
                                                 force_retrain=self._force_retrain,
                                                 reduced_num_users_items=reduced_num_users_items)


def generate_latent_factors_from_data(dataset_name, datapath, params, random,
                                      force_retrain=False, reduced_num_users_items=None):
    &#34;&#34;&#34;Create latent factors based on a dataset.&#34;&#34;&#34;
    model_file = os.path.join(datapath, &#39;fm_model.npz&#39;)
    if not os.path.isfile(model_file) or force_retrain:
        print(&#39;Did not find model file at {}, loading data for training&#39;.format(model_file))

        users, items, ratings = data_utils.read_dataset(dataset_name)
        print(&#39;Initializing latent factor model&#39;)
        recommender = LibFM(**params)
        recommender.reset(users, items, ratings)
        print(&#39;Training latent factor model with parameters: {}&#39;.format(params))

        global_bias, weights, pairwise_interactions = recommender.model_parameters()
        if len(weights) == 0:
            weights = np.zeros(pairwise_interactions.shape[0])

        # TODO: this logic is only correct if there are no additional user/item/rating features
        # Note that we discard the original data&#39;s user_ids and item_ids at this step
        user_indices = np.arange(params[&#39;max_num_users&#39;])
        item_indices = np.arange(params[&#39;max_num_users&#39;],
                                 params[&#39;max_num_users&#39;] + params[&#39;max_num_items&#39;])

        user_factors = pairwise_interactions[user_indices]
        user_bias = weights[user_indices]
        item_factors = pairwise_interactions[item_indices]
        item_bias = weights[item_indices]
        offset = global_bias
        params = json.dumps(recommender.hyperparameters)

        np.savez(model_file, user_factors=user_factors, user_bias=user_bias,
                 item_factors=item_factors, item_bias=item_bias, offset=offset,
                 params=params)

    else:
        model = np.load(model_file)
        print(&#39;Loading model from {} trained via:\n{}.&#39;.format(model_file, model[&#39;params&#39;]))

        user_factors = model[&#39;user_factors&#39;]
        user_bias = model[&#39;user_bias&#39;]
        item_factors = model[&#39;item_factors&#39;]
        item_bias = model[&#39;item_bias&#39;]
        offset = model[&#39;offset&#39;]

    if reduced_num_users_items is not None:
        num_users, num_items = reduced_num_users_items
        # TODO: may want to reduce the number in some other way
        # e.g. related to popularity
        user_indices = random.choice(user_factors.shape[0], size=num_users,
                                     replace=False)
        item_indices = random.choice(item_factors.shape[0], size=num_items,
                                     replace=False)
        user_factors = user_factors[user_indices]
        user_bias = user_bias[user_indices]
        item_factors = item_factors[item_indices]
        item_bias = item_bias[item_indices]

    return user_factors, user_bias, item_factors, item_bias, offset</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="reclab.environments.latent_factors.generate_latent_factors_from_data"><code class="name flex">
<span>def <span class="ident">generate_latent_factors_from_data</span></span>(<span>dataset_name, datapath, params, random, force_retrain=False, reduced_num_users_items=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Create latent factors based on a dataset.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_latent_factors_from_data(dataset_name, datapath, params, random,
                                      force_retrain=False, reduced_num_users_items=None):
    &#34;&#34;&#34;Create latent factors based on a dataset.&#34;&#34;&#34;
    model_file = os.path.join(datapath, &#39;fm_model.npz&#39;)
    if not os.path.isfile(model_file) or force_retrain:
        print(&#39;Did not find model file at {}, loading data for training&#39;.format(model_file))

        users, items, ratings = data_utils.read_dataset(dataset_name)
        print(&#39;Initializing latent factor model&#39;)
        recommender = LibFM(**params)
        recommender.reset(users, items, ratings)
        print(&#39;Training latent factor model with parameters: {}&#39;.format(params))

        global_bias, weights, pairwise_interactions = recommender.model_parameters()
        if len(weights) == 0:
            weights = np.zeros(pairwise_interactions.shape[0])

        # TODO: this logic is only correct if there are no additional user/item/rating features
        # Note that we discard the original data&#39;s user_ids and item_ids at this step
        user_indices = np.arange(params[&#39;max_num_users&#39;])
        item_indices = np.arange(params[&#39;max_num_users&#39;],
                                 params[&#39;max_num_users&#39;] + params[&#39;max_num_items&#39;])

        user_factors = pairwise_interactions[user_indices]
        user_bias = weights[user_indices]
        item_factors = pairwise_interactions[item_indices]
        item_bias = weights[item_indices]
        offset = global_bias
        params = json.dumps(recommender.hyperparameters)

        np.savez(model_file, user_factors=user_factors, user_bias=user_bias,
                 item_factors=item_factors, item_bias=item_bias, offset=offset,
                 params=params)

    else:
        model = np.load(model_file)
        print(&#39;Loading model from {} trained via:\n{}.&#39;.format(model_file, model[&#39;params&#39;]))

        user_factors = model[&#39;user_factors&#39;]
        user_bias = model[&#39;user_bias&#39;]
        item_factors = model[&#39;item_factors&#39;]
        item_bias = model[&#39;item_bias&#39;]
        offset = model[&#39;offset&#39;]

    if reduced_num_users_items is not None:
        num_users, num_items = reduced_num_users_items
        # TODO: may want to reduce the number in some other way
        # e.g. related to popularity
        user_indices = random.choice(user_factors.shape[0], size=num_users,
                                     replace=False)
        item_indices = random.choice(item_factors.shape[0], size=num_items,
                                     replace=False)
        user_factors = user_factors[user_indices]
        user_bias = user_bias[user_indices]
        item_factors = item_factors[item_indices]
        item_bias = item_bias[item_indices]

    return user_factors, user_bias, item_factors, item_bias, offset</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="reclab.environments.latent_factors.DatasetLatentFactor"><code class="flex name class">
<span>class <span class="ident">DatasetLatentFactor</span></span>
<span>(</span><span>name, latent_dim=128, datapath='/home/sarah/recsys/recsys-eval/reclab/../data', force_retrain=False, max_num_users=inf, max_num_items=inf, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>An environment where user behavior is based on a dataset.</p>
<p>Latent factor model of behavior with parameters fit directly from full dataset.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>The name of the dataset. Must be one of: 'ml-100k', 'ml-10m', 'lastfm'.</dd>
<dt><strong><code>latent_dim</code></strong> :&ensp;<code>int</code></dt>
<dd>Size of latent factors p, q.</dd>
<dt><strong><code>datapath</code></strong> :&ensp;<code>str</code></dt>
<dd>The path to the directory containing datafiles</dd>
<dt><strong><code>force_retrain</code></strong> :&ensp;<code>bool</code></dt>
<dd>Forces retraining the latent factor model</dd>
<dt><strong><code>max_num_users</code></strong> :&ensp;<code>int</code></dt>
<dd>The maximum number of users for the environment, if not the number in the dataset.</dd>
<dt><strong><code>max_num_items</code></strong> :&ensp;<code>int</code></dt>
<dd>The maximum number of items for the environment, if not the number in the dataset.</dd>
</dl>
<p>Create a ML100K Latent Factor environment.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DatasetLatentFactor(LatentFactorBehavior):
    &#34;&#34;&#34;An environment where user behavior is based on a dataset.

    Latent factor model of behavior with parameters fit directly from full dataset.

    Parameters
    ----------
    name : str
        The name of the dataset. Must be one of: &#39;ml-100k&#39;, &#39;ml-10m&#39;, &#39;lastfm&#39;.
    latent_dim : int
        Size of latent factors p, q.
    datapath : str
        The path to the directory containing datafiles
    force_retrain : bool
        Forces retraining the latent factor model
    max_num_users : int
        The maximum number of users for the environment, if not the number in the dataset.
    max_num_items : int
        The maximum number of items for the environment, if not the number in the dataset.

    &#34;&#34;&#34;

    def __init__(self, name, latent_dim=128, datapath=data_utils.DATA_DIR, force_retrain=False,
                 max_num_users=np.inf, max_num_items=np.inf, **kwargs):
        &#34;&#34;&#34;Create a ML100K Latent Factor environment.&#34;&#34;&#34;
        self.dataset_name = name
        if name == &#39;ml-100k&#39;:
            self.datapath = os.path.expanduser(os.path.join(datapath, &#39;ml-100k&#39;))
            latent_dim = 100 if latent_dim is None else latent_dim
            self._full_num_users = 943
            self._full_num_items = 1682
            # These parameters are the result of tuning.
            reg = 0.1
            learn_rate = 0.005
            self.train_params = dict(bias_reg=reg, one_way_reg=reg, two_way_reg=reg,
                                     learning_rate=learn_rate, num_iter=100)
        elif name == &#39;ml-10m&#39;:
            self.datapath = os.path.expanduser(os.path.join(datapath, &#39;ml-10M100K&#39;))
            latent_dim = 128 if latent_dim is None else latent_dim
            self._full_num_users = 69878
            self._full_num_items = 10677
            # these parameters are presented in &#34;On the Difficulty of Baselines&#34; by Rendle et al.
            reg = 0.04
            learn_rate = 0.003
            self.train_params = dict(bias_reg=reg, one_way_reg=reg, two_way_reg=reg,
                                     learning_rate=learn_rate, num_iter=128)
        elif name == &#39;lastfm&#39;:
            self.datapath = os.path.expanduser(os.path.join(datapath, &#39;lastfm-dataset-1K&#39;))
            latent_dim = 128 if latent_dim is None else latent_dim
            self._full_num_users = 992
            self._full_num_items = 177023
            # These parameters are presented in &#34;Recommendations and User Agency&#34; by Dean et al.
            reg = 0.08
            learn_rate = 0.001
            self.train_params = dict(bias_reg=reg, one_way_reg=reg, two_way_reg=reg,
                                     learning_rate=learn_rate, num_iter=128)
        else:
            raise ValueError(&#39;dataset name not recognized&#39;)
        self._force_retrain = force_retrain

        num_users = min(self._full_num_users, max_num_users)
        num_items = min(self._full_num_items, max_num_items)

        super().__init__(latent_dim, num_users, num_items, **kwargs)

    @property
    def name(self):
        &#34;&#34;&#34;Name of environment, used for saving.&#34;&#34;&#34;
        return &#39;latent-{}&#39;.format(self.dataset_name)

    def _generate_latent_factors(self):
        full_model_params = dict(num_user_features=0, num_item_features=0, num_rating_features=0,
                                 max_num_users=self._full_num_users,
                                 max_num_items=self._full_num_items,
                                 num_two_way_factors=self._latent_dim, **self.train_params)
        if self._num_users &lt; self._full_num_users or self._num_items &lt; self._full_num_items:
            reduced_num_users_items = (min(self._num_users, self._full_num_users),
                                       min(self._num_items, self._full_num_items))
        else:
            reduced_num_users_items = None
        # TODO: This is another source of randomness that isn&#39;t accounted for by our seeds.
        # We probably want to make it more obvious that we need to snapshot the output when
        # we want consistency across experiments.
        return generate_latent_factors_from_data(self.dataset_name, self.datapath,
                                                 full_model_params, self._init_random,
                                                 force_retrain=self._force_retrain,
                                                 reduced_num_users_items=reduced_num_users_items)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="reclab.environments.latent_factors.LatentFactorBehavior" href="#reclab.environments.latent_factors.LatentFactorBehavior">LatentFactorBehavior</a></li>
<li><a title="reclab.environments.environment.DictEnvironment" href="environment.html#reclab.environments.environment.DictEnvironment">DictEnvironment</a></li>
<li><a title="reclab.environments.environment.Environment" href="environment.html#reclab.environments.environment.Environment">Environment</a></li>
<li>abc.ABC</li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="reclab.environments.latent_factors.LatentFactorBehavior" href="#reclab.environments.latent_factors.LatentFactorBehavior">LatentFactorBehavior</a></b></code>:
<ul class="hlist">
<li><code><a title="reclab.environments.latent_factors.LatentFactorBehavior.close" href="environment.html#reclab.environments.environment.Environment.close">close</a></code></li>
<li><code><a title="reclab.environments.latent_factors.LatentFactorBehavior.dense_ratings" href="environment.html#reclab.environments.environment.DictEnvironment.dense_ratings">dense_ratings</a></code></li>
<li><code><a title="reclab.environments.latent_factors.LatentFactorBehavior.items" href="environment.html#reclab.environments.environment.DictEnvironment.items">items</a></code></li>
<li><code><a title="reclab.environments.latent_factors.LatentFactorBehavior.name" href="environment.html#reclab.environments.environment.Environment.name">name</a></code></li>
<li><code><a title="reclab.environments.latent_factors.LatentFactorBehavior.online_users" href="environment.html#reclab.environments.environment.DictEnvironment.online_users">online_users</a></code></li>
<li><code><a title="reclab.environments.latent_factors.LatentFactorBehavior.ratings" href="environment.html#reclab.environments.environment.DictEnvironment.ratings">ratings</a></code></li>
<li><code><a title="reclab.environments.latent_factors.LatentFactorBehavior.reset" href="environment.html#reclab.environments.environment.DictEnvironment.reset">reset</a></code></li>
<li><code><a title="reclab.environments.latent_factors.LatentFactorBehavior.seed" href="environment.html#reclab.environments.environment.DictEnvironment.seed">seed</a></code></li>
<li><code><a title="reclab.environments.latent_factors.LatentFactorBehavior.step" href="environment.html#reclab.environments.environment.DictEnvironment.step">step</a></code></li>
<li><code><a title="reclab.environments.latent_factors.LatentFactorBehavior.users" href="environment.html#reclab.environments.environment.DictEnvironment.users">users</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="reclab.environments.latent_factors.LatentFactorBehavior"><code class="flex name class">
<span>class <span class="ident">LatentFactorBehavior</span></span>
<span>(</span><span>latent_dim, num_users, num_items, rating_frequency=0.02, num_init_ratings=0, noise=0.0, memory_length=0, affinity_change=0.0, boredom_threshold=0, boredom_penalty=0.0, user_dist_choice='uniform')</span>
</code></dt>
<dd>
<div class="desc"><p>An environment where users and items have latent factors and biases.</p>
<p>Ratings are generated as
r = clip( <p_u, q_i> + b_u + b_i + b_0 )
where p_u is a user's latent factor, q_i is an item's latent factor,
b_u is a user bias, b_i is an item bias, and b_0 is a global bias.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>latent_dim</code></strong> :&ensp;<code>int</code></dt>
<dd>Size of latent factors p, q.</dd>
<dt><strong><code>num_users</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of users in the environment.</dd>
<dt><strong><code>num_items</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of items in the environment.</dd>
<dt><strong><code>rating_frequency</code></strong> :&ensp;<code>float</code></dt>
<dd>The proportion of users that will need a recommendation at each step.
Must be between 0 and 1.</dd>
<dt><strong><code>num_init_ratings</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of ratings available from the start. User-item pairs are randomly selected.</dd>
<dt><strong><code>noise</code></strong> :&ensp;<code>float</code></dt>
<dd>The standard deviation of the noise added to ratings.</dd>
<dt><strong><code>affinity_change</code></strong> :&ensp;<code>float</code></dt>
<dd>How much the user's latent factor is shifted towards that of an item.</dd>
<dt><strong><code>memory_length</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of recent items a user remembers which affect the rating.</dd>
<dt><strong><code>boredom_threshold</code></strong> :&ensp;<code>int</code></dt>
<dd>The size of the inner product between a new item and an item in the
user's history to trigger a boredom response.</dd>
<dt><strong><code>boredom_penalty</code></strong> :&ensp;<code>float</code></dt>
<dd>The factor on the penalty on the rating when a user is bored. The penalty
is the average of the values which exceed the boredom_threshold, and the decrease
in rating is the penalty multiplied by this factor.</dd>
<dt><strong><code>user_dist_choice</code></strong> :&ensp;<code>str</code></dt>
<dd>The choice of user distribution for selecting online users. By default, the subset of
online users is chosen from a uniform distribution. Currently supports normal and lognormal.</dd>
</dl>
<p>Create a Latent Factor environment.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LatentFactorBehavior(environment.DictEnvironment):
    &#34;&#34;&#34;An environment where users and items have latent factors and biases.

    Ratings are generated as
    r = clip( &lt;p_u, q_i&gt; + b_u + b_i + b_0 )
    where p_u is a user&#39;s latent factor, q_i is an item&#39;s latent factor,
    b_u is a user bias, b_i is an item bias, and b_0 is a global bias.

    Parameters
    ----------
    latent_dim : int
        Size of latent factors p, q.
    num_users : int
        The number of users in the environment.
    num_items : int
        The number of items in the environment.
    rating_frequency : float
        The proportion of users that will need a recommendation at each step.
        Must be between 0 and 1.
    num_init_ratings : int
        The number of ratings available from the start. User-item pairs are randomly selected.
    noise : float
        The standard deviation of the noise added to ratings.
    affinity_change : float
        How much the user&#39;s latent factor is shifted towards that of an item.
    memory_length : int
        The number of recent items a user remembers which affect the rating.
    boredom_threshold : int
        The size of the inner product between a new item and an item in the
        user&#39;s history to trigger a boredom response.
    boredom_penalty : float
        The factor on the penalty on the rating when a user is bored. The penalty
        is the average of the values which exceed the boredom_threshold, and the decrease
        in rating is the penalty multiplied by this factor.
    user_dist_choice : str
        The choice of user distribution for selecting online users. By default, the subset of
        online users is chosen from a uniform distribution. Currently supports normal and lognormal.

    &#34;&#34;&#34;

    def __init__(self, latent_dim, num_users, num_items,
                 rating_frequency=0.02, num_init_ratings=0,
                 noise=0.0, memory_length=0, affinity_change=0.0,
                 boredom_threshold=0, boredom_penalty=0.0, user_dist_choice=&#39;uniform&#39;):
        &#34;&#34;&#34;Create a Latent Factor environment.&#34;&#34;&#34;
        super().__init__(rating_frequency, num_init_ratings, memory_length, user_dist_choice)
        self._latent_dim = latent_dim
        self._num_users = num_users
        self._num_items = num_items
        self._noise = noise
        self._affinity_change = affinity_change
        self._boredom_threshold = boredom_threshold
        self._boredom_penalty = boredom_penalty
        if self._memory_length &gt; 0:
            self._boredom_penalty /= self._memory_length
        self._user_factors = None
        self._user_biases = None
        self._item_factors = None
        self._item_biases = None
        self._offset = None

    @property
    def name(self):
        &#34;&#34;&#34;Name of environment, used for saving.&#34;&#34;&#34;
        return &#39;latent&#39;

    def _get_dense_ratings(self):  # noqa: D102
        ratings = (self._user_factors @ self._item_factors.T + self._user_biases[:, np.newaxis] +
                   self._item_biases[np.newaxis, :] + self._offset)
        # Compute the boredom penalties.
        item_norms = np.linalg.norm(self._item_factors, axis=1)
        normalized_items = self._item_factors / item_norms[:, np.newaxis]
        similarities = normalized_items @ normalized_items.T
        similarities -= self._boredom_threshold
        similarities[similarities &lt; 0] = 0
        penalties = self._boredom_penalty * similarities
        for user_id in range(self._num_users):
            for item_id in self._user_histories[user_id]:
                if item_id is not None:
                    ratings[user_id] -= penalties[item_id]

        return ratings

    def _get_rating(self, user_id, item_id):
        &#34;&#34;&#34;Compute user&#39;s rating of item based on model.

        Parameters
        ----------
        user_id : int
            The id of the user making the rating.
        item_id : int
            The id of the item being rated.

        Returns
        -------
        rating : int
            The rating the item was given by the user.

        &#34;&#34;&#34;
        raw_rating = (self._user_factors[user_id] @ self._item_factors[item_id]
                      + self._user_biases[user_id] + self._item_biases[item_id] + self._offset)

        # Compute the boredom penalty.
        boredom_penalty = 0
        for item_id_hist in self._user_histories[user_id]:
            item_factor = self._item_factors[item_id_hist]
            if item_factor is not None:
                similarity = ((self._item_factors[item_id] @ item_factor)
                              / np.linalg.norm(item_factor)
                              / np.linalg.norm(self._item_factors[item_id]))
                if similarity &gt; self._boredom_threshold:
                    boredom_penalty += (similarity - self._boredom_threshold)
        boredom_penalty *= self._boredom_penalty
        rating = np.clip(raw_rating - boredom_penalty + self._dynamics_random.randn() *
                         self._noise, 1, 5)

        return rating

    def _rate_item(self, user_id, item_id):
        &#34;&#34;&#34;Get a user to rate an item and update the internal rating state.

        Parameters
        ----------
        user_id : int
            The id of the user making the rating.
        item_id : int
            The id of the item being rated.

        Returns
        -------
        rating : int
            The rating the item was given by the user.

        &#34;&#34;&#34;
        rating = self._get_rating(user_id, item_id)

        # Updating underlying affinity
        self._user_factors[user_id] = ((1.0 - self._affinity_change) * self._user_factors[user_id]
                                       + self._affinity_change * self._item_factors[item_id])
        return rating

    def _reset_state(self):
        &#34;&#34;&#34;Reset the state of the environment.&#34;&#34;&#34;
        user_factors, user_bias, item_factors, item_bias, offset = self._generate_latent_factors()
        self._user_factors = user_factors
        self._user_biases = user_bias
        self._item_factors = item_factors
        self._item_biases = item_bias
        self._offset = offset

        self._users = collections.OrderedDict((user_id, np.zeros(0))
                                              for user_id in range(self._num_users))
        self._items = collections.OrderedDict((item_id, np.zeros(0))
                                              for item_id in range(self._num_items))

    def _generate_latent_factors(self):
        &#34;&#34;&#34;Generate random latent factors.&#34;&#34;&#34;
        # Initialization size determined such that ratings generally fall in 0-5 range
        factor_sd = np.sqrt(np.sqrt(0.5 / self._latent_dim))
        # User latent factors are normally distributed
        user_bias = self._init_random.normal(loc=0., scale=0.5, size=self._num_users)
        user_factors = self._init_random.normal(loc=0., scale=factor_sd,
                                                size=(self._num_users, self._latent_dim))
        # Item latent factors are normally distributed
        item_bias = self._init_random.normal(loc=0., scale=0.5, size=self._num_items)
        item_factors = self._init_random.normal(loc=0., scale=factor_sd,
                                                size=(self._num_items, self._latent_dim))
        # Shift up the mean
        offset = 3.0
        return user_factors, user_bias, item_factors, item_bias, offset</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="reclab.environments.environment.DictEnvironment" href="environment.html#reclab.environments.environment.DictEnvironment">DictEnvironment</a></li>
<li><a title="reclab.environments.environment.Environment" href="environment.html#reclab.environments.environment.Environment">Environment</a></li>
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="reclab.environments.latent_factors.DatasetLatentFactor" href="#reclab.environments.latent_factors.DatasetLatentFactor">DatasetLatentFactor</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="reclab.environments.environment.DictEnvironment" href="environment.html#reclab.environments.environment.DictEnvironment">DictEnvironment</a></b></code>:
<ul class="hlist">
<li><code><a title="reclab.environments.environment.DictEnvironment.close" href="environment.html#reclab.environments.environment.Environment.close">close</a></code></li>
<li><code><a title="reclab.environments.environment.DictEnvironment.dense_ratings" href="environment.html#reclab.environments.environment.DictEnvironment.dense_ratings">dense_ratings</a></code></li>
<li><code><a title="reclab.environments.environment.DictEnvironment.items" href="environment.html#reclab.environments.environment.DictEnvironment.items">items</a></code></li>
<li><code><a title="reclab.environments.environment.DictEnvironment.name" href="environment.html#reclab.environments.environment.Environment.name">name</a></code></li>
<li><code><a title="reclab.environments.environment.DictEnvironment.online_users" href="environment.html#reclab.environments.environment.DictEnvironment.online_users">online_users</a></code></li>
<li><code><a title="reclab.environments.environment.DictEnvironment.ratings" href="environment.html#reclab.environments.environment.DictEnvironment.ratings">ratings</a></code></li>
<li><code><a title="reclab.environments.environment.DictEnvironment.reset" href="environment.html#reclab.environments.environment.DictEnvironment.reset">reset</a></code></li>
<li><code><a title="reclab.environments.environment.DictEnvironment.seed" href="environment.html#reclab.environments.environment.DictEnvironment.seed">seed</a></code></li>
<li><code><a title="reclab.environments.environment.DictEnvironment.step" href="environment.html#reclab.environments.environment.DictEnvironment.step">step</a></code></li>
<li><code><a title="reclab.environments.environment.DictEnvironment.users" href="environment.html#reclab.environments.environment.DictEnvironment.users">users</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="reclab.environments" href="index.html">reclab.environments</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="reclab.environments.latent_factors.generate_latent_factors_from_data" href="#reclab.environments.latent_factors.generate_latent_factors_from_data">generate_latent_factors_from_data</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="reclab.environments.latent_factors.DatasetLatentFactor" href="#reclab.environments.latent_factors.DatasetLatentFactor">DatasetLatentFactor</a></code></h4>
</li>
<li>
<h4><code><a title="reclab.environments.latent_factors.LatentFactorBehavior" href="#reclab.environments.latent_factors.LatentFactorBehavior">LatentFactorBehavior</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.4</a>.</p>
</footer>
</body>
</html>